<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:ops="http://www.idpf.org/2007/ops" xml:lang="ja">
<head>
  <meta charset="UTF-8" />
  <script>MathJax = { tex: { inlineMath: [['\\(', '\\)']] }, svg: { fontCache: 'global' } };</script>
  <script type="text/javascript" id="MathJax-script" async="true" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="stylesheet" type="text/css" href="oreilly.css" />
  <meta name="generator" content="Re:VIEW" />
  <title>演習問題の解答</title>
</head>
<body>
<h1><a id="h"></a>演習問題の解答</h1>
<div class="note">
<p>コードを書く演習問題の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックに掲載されている。</p>
</div>

<h2><a id="h-1"></a>1章：機械学習の現状</h2>
<ul>
<li>1. 機械学習とは、データから学習できるシステムを作ることである。学習とは、何らかの測定手段に基づき、あるタスクを処理した成績が上がるという意味である。</li>
<li>2. 次の通り。　<ul>
<li>アルゴリズムを使ったソリューションがない複雑な問題の解決。</li>
<li>思いつきの規則が延々と続くものに代わるモジュールの開発。</li>
<li>変動する環境に合わせて自分を修正できるシステムの開発。</li>
<li>人間の学習の支援（たとえばデータマイニング）。</li>
</ul>
</li>
<li>3. 個々のインスタンスに問題の答えが含まれている訓練セット（これをラベルと呼ぶ）。</li>
<li>4. 回帰と分類。</li>
<li>5. クラスタリング、可視化、次元削減、相関ルール学習、異常検知、新規検知。</li>
<li>6. 強化学習。未知の領域で歩き方を探索して学習できるようにしたければ、それは強化学習が解決を目指すタイプの問題の典型例である。教師あり学習、教師なし学習の問題として、この問題を表現することもできるが、強化学習よりも不自然になる。</li>
<li>7. 集団の定義がわからない場合は、クラスタリングアルゴリズム（教師なし学習）を使って似ている顧客のクラスタに顧客を分割する。しかし、集団への分類方法がわかっている場合には、各集団のデータ例を多数与えて訓練した分類アルゴリズム（教師あり学習）を使えば、すべての顧客をその集団に分類できる。</li>
<li>8. 典型的な教師あり学習問題である。ラベル（スパムかハムか）を付けたメールの例を多数与えてアルゴリズム訓練すればよい。</li>
<li>9. オンライン学習システムは、バッチ学習システムとは異なり、差分データで学習できる。そのため、データが変化するシステムや自律的なシステムでオンライン学習システムを使えば、機敏に学習できる。オンライン学習システムを使えば、極端に大規模なデータによる訓練も実現できる。</li>
<li>10. コンピュータのメインメモリに収まりきらないくらいの大量のデータで訓練できるシステム。データをミニバッチに分割し、オンライン学習のテクニックを使ってそのミニバッチから学習する。</li>
<li>11. インスタンスベース学習。訓練データを丸暗記させた上で新しいインスタンスを与えると、類似度の尺度を使って学習したインスタンスのなかで与えられたインスタンスにもっとも近いものを見つけ、それを使って予測する。</li>
<li>12. モデルは1つ以上のモデルパラメータ（たとえば、線形モデルの直線の傾き）を持っており、新しいインスタンスに対するモデルの予測はモデルパラメータ次第で決まる。学習アルゴリズムは、モデルが新しいインスタンスに対してうまく汎化するように、これらのパラメータの最適値を探す。<br />ハイパーパラメータ（たとえば、適用する正則化の程度）は、学習アルゴリズム自体のパラメータで、モデルのパラメータではない。</li>
<li>13. 探すのは、新しいインスタンスに対してモデルがうまく汎化する最適なモデルパラメータの値である。<br />そのために、訓練データに対する予測のまずさを計測して数値化するコスト関数が最小になるようにシステムを訓練する。ただし、モデルが正則化されている場合は、コスト関数の値にモデルの複雑度に対するペナルティを加算する。<br />学習アルゴリズムが見つけたパラメータを組み込んだ予測関数に新インスタンスの特徴量を与えた計算結果が予測になる。</li>
<li>14. データの欠落、データの品質の低さ、全体を代表していないデータ、関係のない特徴量、訓練データに過小適合する単純すぎるモデル、訓練データに過学習した複雑すぎるモデル。</li>
<li>15. 起きていることは、訓練データの過学習（または、極端に好都合な訓練データが与えられた）。<br />過学習の解決方法は、訓練データを増やす、モデルを単純化する（具体的には、より単純なアルゴリズムを選ぶ、使うパラメータや特徴量の数を減らす、モデルを正則化するなど）、訓練データのノイズを削減するなど。</li>
<li>16. モデルを本番稼働させる前に、モデルが新しいインスタンスに対して示す汎化誤差を推計するために使われるデータセット。<br />訓練セットを過学習して汎化性能の低いモデルを作らないようにするために必要。</li>
<li>17. モデルの比較。具体的には、最良のモデルを選んだり、ハイパーパラメータを調整したりするために使う。</li>
<li>18. 訓練データと検証、テストデータの間に大きな不一致が生まれそうなときに使われるデータセット。<br />検証、テストデータセットはできる限り本番稼働時に使われるデータに近づけるようにすべきだが、訓練データセットは必ずしもそうではないので、ミスマッチ（齟齬）が生まれる。訓練－開発セットは、訓練セットの一部でそこから取り分けられたものである（モデルの訓練には使われない）。モデルは訓練－開発セット以外の訓練セットで訓練され、訓練－開発セットと検証セットの両方で評価される。モデルが訓練セットでは性能が高いのに訓練－開発セットでは性能が低い場合、モデルはおそらく訓練セットを過学習している。それに対し、訓練セット、訓練－開発セットでは性能が高いのに検証セットでは性能が低い場合、訓練データと検証、テストデータの間に大きなデータミスマッチがある。その場合、検証、テストデータと似たものになるように訓練データを改善した方がよい。</li>
<li>19. テストセットを過学習し、測定される汎化誤差が楽観的過ぎるものになることがある（予想よりも性能の低いモデルを本番稼働してしまう危険がある）。</li>
</ul>

<h2><a id="h-2"></a>2章：エンドツーエンドの機械学習プロジェクト</h2>
<p><a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-3"></a>3章：分類</h2>
<p><a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-4"></a>4章：モデルの訓練</h2>
<ul>
<li>1. 確率的勾配降下法やミニバッチ勾配降下法。訓練セットがメモリに収まりきる場合には、おそらくバッチ勾配降下法も使える。しかし、正規方程式やSVDは、特徴量数の増加とともに計算量があっという間に大きくなる（二乗よりも大きなオーダーで）ので使えない。</li>
<li>2. 勾配降下法。コスト関数が引き延ばされた丼のような形になり、勾配降下法が収束するまでの時間が長くなる。<br />対処方法は、モデルを訓練する前にデータをスケーリングすることである。ちなみに、正規方程式は、スケーリングせずに正しく動作する。特徴量がスケーリングされていないと、正則化されたモデルは最適解ではないところに収束する恐れも出てくる。正則化は大きなペナルティを与えるため、値が小さい特徴量は、値が大きい特徴量と比べて無視されがちになる。</li>
<li>3. コスト関数が凸関数<a id="fnb-f1" href="#fn-f1" class="noteref" epub:type="noteref">*1</a>なので、そのようなことはない。</li>
<li>4. 最適化モデルが凸関数で（線形回帰やロジスティック回帰のように）、学習率があまり高すぎなければ、すべての勾配降下法アルゴリズムが全体の最適値に近づき、同じようなモデルを作る。しかし、学習率を次第に小さくしていかない限り、確率的GDやミニバッチGDは決して収束せず、全体の最適値の上下を飛び回ることになる。つまり、非常に長時間実行したとしても、これらの勾配降下法アルゴリズムはわずかに異なるモデルを作り出す。</li>
<li>5. 学習率が高すぎてアルゴリズムが発散している可能性がある。<br />訓練誤差も上がっているようなら、明らかに学習率に問題があるので下げなければならない。訓練誤差が上がらないなら、モデルが訓練セットを過学習しているので、訓練を中止すべきだ。</li>
<li>6. よくない。<br />確率的勾配降下法とミニバッチ勾配降下法は無作為にインスタンスを選択しているため、訓練するたびに誤差が下がる保証はない。検証セットに対する誤差が上がったときにすぐに訓練を中止すると、最適値にまだ達していない危険性がある。<br />定期的にモデルを保存し、長期に渡って進歩がなくなったら（つまり、最高記録を抜く可能性がなさそうになったら）、保存しているモデルのなかでもっともよいものに戻ればよい。</li>
<li>7. 次の通り。　<ul>
<li>確率的勾配降下法、場合によってはミニバッチ勾配降下法。<br />確率的勾配降下法は、1度に1個の訓練インスタンスしか使わないため、訓練イテレーションがもっとも短時間で終わり、全体の最適値の近くに達するのも一般にもっとも速い（ミニバッチサイズが非常に小さいミニバッチGDが最速になる場合もある）。</li>
<li>収束しない。<br />実際に収束する勾配降下法は、バッチ勾配降下法だけである（しかも、十分な訓練時間を与える必要がある）。確率的GDとミニバッチGDは、学習率を次第に下げない限り最適値の周辺で上下に変動する。</li>
</ul>
</li>
<li>8. 検証誤差が訓練誤差よりもかなり大きい場合、モデルが訓練セットを過学習していると考えられる。解決方法は次の通り。<ul>
<li>多項回帰モデルの次数を下げる。次数が低く自由度が低いモデルは、過学習を起こしにくい。</li>
<li>モデルを正則化する。たとえば、コスト関数に<span class="equation">\( \ell_2 \)</span>正則化（Ridge）か<span class="equation">\( \ell_1 \)</span>正則化（Lasso）を加える。これもモデルの自由度を下げる。</li>
<li>訓練セットのサイズを大きくする。</li>
</ul>
</li>
<li>9. バイアスが高い（モデルが訓練セットに対して過小適合しているため）。<br /><span class="equation">\( \alpha \)</span>は下げるべき。</li>
<li>10. 次の通り。<ul>
<li>正則化されているモデルはされていないモデルよりも性能が高くなるので、一般にプレーンな線形回帰よりもRidge回帰を使うべきだ。</li>
<li>Lasso回帰は小さな重みを0にする<span class="equation">\( \ell_1 \)</span>正則化を使っているため、重要な重み以外はすべての重みが0になっている疎なモデルを作りやすい。実際に意味のある特徴量はわずかなのではないかと思われるときには、Lasso回帰を使えば自動的に特徴量を選択できる。そうでなければ、Ridge回帰を使った方がよい。</li>
<li>一般にLassoよりもElastic Netの方がよい。Lasso回帰は、複数の特徴量に強い相関がある場合や訓練インスタンスの数よりも特徴量の数が多い場合に挙動がおかしくなる。しかし、Elastic Netの方が調整しなければならないハイパーパラメータが多い。挙動がおかしくならないLassoがほしい場合には、<code class="tt">l1_ratio</code>が1に近いElastic Netを使えばよい。</li>
</ul>
</li>
<li>11. 2つのロジスティック回帰分類器を訓練すべき。<br />屋外と屋内、日中と夜間は相互排他的なクラスではない（つまり、日中の屋外、日中の屋内などの4種類の組み合わせがすべてあり得る）ので、多クラス出力できないソフトマックス回帰分類器は使えない。</li>
<li>12. <a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</li>
</ul>
<div class="footnote" epub:type="footnote" id="fn-f1"><p class="footnote">[*1] 曲線上の任意の2点の間に直線を引いたときに、直線と曲線が決して交わらない。</p></div>

<h2><a id="h-5"></a>5章：サポートベクトルマシン（SVM）</h2>
<ul>
<li>1. クラスとクラスの間にできる限り太い「道」を通そうとすること、つまり、訓練インスタンスを2つのクラスに分ける決定境界の間にできる限り大きいマージンを確保することである。<br />ソフトマージン分類では、2つのクラスの完全な分離とできる限り太い道を作ることとの間で妥協点を見つける（つまり、一部のインスタンスは道に入り込んでしまう）。非線形データセットを訓練するときにカーネルを使うのも重要なポイントである。</li>
<li>2. SVMを訓練したあとに「道」（前問の解答参照）のなか（境界線上を含む）に入るインスタンスのこと。<br />決定境界はサポートベクトルのみによって決まり、それ<b>以外</b>のインスタンス（道に入っていないインスタンス）の影響を受けない。サポートベクトル<b>以外</b>のインスタンスは、追加、削除しても、道から外れたところで移動しても、決定境界は変わらない。予測の計算に関わるのはサポートベクトルだけであり、訓練セット全体ではない。</li>
<li>3. SVMは、クラスの間にできるかぎり太い「道」を通そうとする（第1問の解答参照）ので、訓練セットがスケーリングされていないと、SVMは小さな特徴量を無視しがちになる（&lt;img&gt;{chap05|mls2_0502}参照）。</li>
<li>4. SVM分類器はテストインスタンスと決定境界の距離を出力できるので、それを確信度のスコアとして使える。<br />ただし、このスコアは、そのクラスに属する推定確率に直接変換できない。scikit-learnでSVMを作るときに<code class="tt">probability=True</code>を設定すると、SVMを訓練したあとで、ロジスティック回帰（訓練データに対する5フォールド交差検証で訓練されている）を使ってSVMのスコアを確率に較正する。この場合、SVMに<code class="tt">predict_proba()</code>、<code class="tt">predict_log_proba()</code>メソッドが追加される。</li>
<li>5. カーネル化SVMが使えるのは双対形式だけである。そのため、この問が成り立つのは線形SVMだけだが、答えは主問題である。SVM問題の主問題の計算量は訓練インスタンスの数<span class="equation">\( m \)</span>に比例するのに対し、双対形式の計算量は<span class="equation">\( m^2 \)</span>と<span class="equation">\( m^3 \)</span>の間の数値に比例する。そのため、インスタンスが数百万個もあるなら、双対形式は遅すぎて使いものにならないので、迷わず主形式を使うべきだ。</li>
<li>6. 正則化しすぎているので、正則化を緩めるために、<code class="tt">gamma</code>か<code class="tt">C</code>、またはその両方を増やす。</li>
<li>7. ハードマージン問題のQPパラメータを<span class="equation">\( \mathbf{H}' \)</span>、<span class="equation">\( \mathbf{f}' \)</span>、<span class="equation">\( \mathbf{A}' \)</span>、<span class="equation">\( \mathbf{b}' \)</span>と呼ぶことにする（「5.4.3 二次計画参照）。ソフトマージン問題のQPパラメータは、<span class="equation">\( m \)</span>個の追加パラメータ（<span class="equation">\( n_p=n+1+m \)</span>）と<span class="equation">\( m \)</span>個の追加制約（<span class="equation">\( n_c=2m \)</span>）を持つ。これらは次のように定義できる。<ul>
<li><span class="equation">\( \mathbf{H} \)</span>は、<span class="equation">\( \mathbf{H}' \)</span>の右に<span class="equation">\( m \)</span>個の0の列、下に<span class="equation">\( m \)</span>個の0の行を追加したものと等しい。<br /><span class="equation">\( \mathbf{H} = \begin{pmatrix}\mathbf{H}' & 0 & \cdots \\ 0 & 0 & \\  \vdots & & \ddots \\ \end{pmatrix} \)</span></li>
<li><span class="equation">\( \mathbf{f} \)</span>は、値がハイパーパラメータ<span class="equation">\( C \)</span>に等しい<span class="equation">\( m \)</span>個の要素を追加した<span class="equation">\( \mathbf{f}' \)</span>と等しい。</li>
<li><span class="equation">\( \mathbf{b} \)</span>は、値が0の<span class="equation">\( m \)</span>個の要素を追加した<span class="equation">\( \mathbf{b}' \)</span>と等しい。</li>
<li><span class="equation">\( \mathbf{A} \)</span>は、<span class="equation">\( \mathbf{A}' \)</span>の右に<span class="equation">\( m\times m \)</span>の単位行列<span class="equation">\( \mathbf{I}_m \)</span>、その真下に<span class="equation">\( -\mathbf{I}_m \)</span>、その他の部分を0で埋めたものと等しい。<span class="equation">\( \mathbf{A} = \begin{pmatrix}\mathbf{A}' & \mathbf{I}_{m} \\ 0 & {- \mathbf{I}_{m}} \\ \end{pmatrix} \)</span></li>
</ul>
</li>
</ul>
<p>問8から問10の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-6"></a>6章：決定木</h2>
<ul>
<li>1. 約20。<br /><span class="equation">\( m \)</span>個の葉を持つよくバランスの取れた二分木の深さは、<span class="equation">\( \log_2(m) \)</span><a id="fnb-f2" href="#fn-f2" class="noteref" epub:type="noteref">*2</a>を端数切り上げしたものになる。二分決定木（イエスかノーしか判断しない決定木。scikit-learnの木はすべてこれである）は、無制限で訓練すると、訓練インスタンスごとに1つの葉を持つことになり、訓練終了時にある程度平衡したものになる。そのため、訓練セットのインスタンスが100万個なら、決定木の深さは<span class="equation">\( \log_2(10^6)\approx 20 \)</span>になる（一般に木は完全な平衡木にならないので、実際にはこれよりも少し多くなる）。</li>
<li>2. 一般に親よりも低い。<br />これは、子のジニ不純度の加重総和が最小になるようにノードを分割するCART訓練アルゴリズムのコスト関数のためである。しかし、ノードのジニ不純度は親のジニ不純度よりも高くなることがある。それは、ほかの子が全体としてのジニ不純度を引き下げる以上にその子のジニ不純度が高い場合だ。たとえば、クラスAのインスタンスを4個、クラスBのインスタンスを1個含むノードについて考えてみよう。そのジニ不純度は、<span class="equation">\( 1-(\frac{1}{5})^2-(\frac{4}{5})^2=0.32 \)</span>である。ここで、データセットは1次元で、インスタンスはA、B、A、A、Aの順で並んでいるものとする。アルゴリズムは、第2インスタンスのあとでこのノードを分割し、A、Bを含む子ノードとA、A、Aを含む子ノードが作られることが確かめられる。最初の子ノードのジニ不純度は、<span class="equation">\( 1-(\frac{1}{2})^2-(\frac{1}{2})^2=0.5 \)</span>で親よりも高い。これは、もう1つのノードが純粋だということによって補償され、ジニ不純度の加重総和は<span class="equation">\( \frac{2}{5}\times 0.5+\frac{3}{5}\times 0=0.2 \)</span>となり、親のジニ不純度よりも低くなっている。</li>
<li>3. よい。<br /><code class="tt">max_depth</code>を下げるとモデルに制約を加え正則化することになる。</li>
<li>4. 意味がない。<br />決定木は、訓練データのスケーリングやセンタリングの影響を受けず、これは長所の1つである。そのため、決定木が訓練セットに過小適合しているからと言って、入力特徴量を増やしても時間の無駄である。</li>
<li>5. 約11.7時間。<br />決定木の訓練の計算量は、<span class="equation">\( O(n\times m\log(m)) \)</span>である。そこで、訓練セットのサイズを10倍にすると、訓練時間は、<span class="equation">\( K=(n\times 10 m\times\log(10m))/(n\times m\times\log(m))=10\times\log(10m)/\log(m) \)</span>倍になる。<span class="equation">\( m=10^6 \)</span>なら、<span class="equation">\( K\approx 11.7 \)</span>となる。</li>
<li>6. かなり下がる。<br />訓練セットのプレソートによって訓練のスピードが上がるのは、訓練セットのインスタンス数が数千個未満のときだけで、インスタンスが100,000個もある場合、<code class="tt">presort=True</code>を指定すると訓練のスピードはかなり下がる。</li>
</ul>
<div class="footnote" epub:type="footnote" id="fn-f2"><p class="footnote">[*2] <span class="equation">\( \log_2 \)</span>は2進対数であり、<span class="equation">\( \log_2(m)=\log(m)/\log(2) \)</span>である。</p></div>
<p>問7、問8の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-7"></a>7章：アンサンブル学習とランダムフォレスト</h2>
<ul>
<li>1. ある。<br />5個のモデルを組み合わせて多数決アンサンブルを作れば、もとの個別のモデルよりもよい結果を生むことが多い。モデルが大きく異なる場合（たとえば、SVM分類器、決定木分類器、ロジスティック回帰分類器など）に高い性能を示すことが多い。異なる訓練インスタンスで訓練するとさらに性能は上がる（バギングやペースティングといったアンサンブルのポイントはここにある）が、そうでなくても、モデルが大きく異なれば、性能は上がる。</li>
<li>2. ハード投票分類器は、アンサンブルに含まれる個々の分類器の投票をただ数えて、もっとも投票の多かったクラスを返す。ソフト投票分類器は、個々の分類器が推計した各クラスに属する確率の平均を計算し、もっとも高い確率が得られたクラスを返す。こうすると、信頼性の高い投票に重みがかかり、性能が上がることが多いが、すべての分類器がクラスに属する確率を推計できなければ使えない（たとえば、scikit-learnでSVM分類機を使うときには、<code class="tt">probability=True</code>をセットしなければならない）</li>
<li>3. 含まれる予測器が互いに独立しているバギングアンサンブルの訓練は、複数のサーバーで分散処理すればスピードを上げられる可能性がある。同じ理由で、ペースティングアンサンブルやランダムフォレストもスピードが上がる可能性がある。しかし、ブースティングアンサンブルの個々の予測器は前の予測器を基礎として作られるため、逐次的な訓練が必要とされ、複数のサーバーの間で訓練を分散処理しても何も得られない。スタッキングアンサンブルの場合、個々の層の予測器はどれも互いに独立しているので、それらを複数のサーバーで並列に訓練することはできる。ただし、ある層の予測器を訓練できるのは、前の層の予測器がすべて訓練されてからである。</li>
<li>4. OOB検証では、バギングアンサンブルに含まれる個々の予測器は、訓練で使われていないインスタンス（それらは取り分けられている）を使って検証される。そのため、別に検証セットを用意しなくても、かなりバイアスの低い形でアンサンブルを検証できる。そのため、訓練のために使えるインスタンスが多くなり、アンサンブルの性能が少し上がる。</li>
<li>5. ランダムフォレストで木を育てるときには、無作為に取り出した特徴量のサブセットだけで個々のノードの分割を判断する。Extra-Treesは、この部分でランダムフォレストと同じであるだけでなく、もう1歩先に進んで、通常のランダムフォレストのように個々の特徴量で可能な限り最良のしきい値を探すのではなく、無作為なしきい値を使う。<br />Extra-Treesは最良のしきい値を探そうとしない分、ランダムフォレストよりも速く訓練できる。しかし、予測を行うときには、ランダムフォレストより速くも遅くもない。</li>
<li>6. 推定器を増やすか、ベース推定器の正則化ハイパーパラメータを下げればよい。また、学習率を少し上げるのもよいだろう。</li>
<li>7. 学習率は下げてみるとよい。また、予測器の台数として適切な値を探るために（たぶん、多過ぎる）早期打ち切りも使ってみるとよい。</li>
</ul>
<p>問8、問9の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-8"></a>8章：次元削減</h2>
<ul>
<li>1. 次の通り。<ul>
<li>主要な理由<ul>
<li>そのあとの訓練アルゴリズムの高速化（場合によってはノイズや重複する特徴量を取り除いて、訓練アルゴリズムの性能が上がる）。</li>
<li>データを可視化し、もっとも重要な特徴量についての理解を深める。</li>
<li>単純にスペースを節約する（圧縮）。</li>
</ul>
</li>
<li>主要な欠点<ul>
<li>重要な情報が失われ、おそらくそのあとの訓練アルゴリズムの性能が下がる。</li>
<li>CPUに負荷をかけることがある。</li>
<li>機械学習パイプラインがある程度複雑化する。</li>
<li>変換後の特徴量が解釈しにくくなることが多い。</li>
</ul>
</li>
</ul>
</li>
<li>2. 低次元空間では存在しない多くの問題が高次元空間では顕在化することを言う。機械学習でもっとも顕著なのは、無作為抽出した高次ベクトルが一般に非常に疎で、過学習のリスクが上がるだけでなく、訓練データが相当豊富になければデータのなかのパターンを見つけにくくなることである。</li>
<li>3. この章で取り上げたアルゴリズムでは、もとに戻せない。<br />これらの場合、次元削減の操作中に一部の情報が失われるので、その操作を完全に復元することはほぼ完全に不可能である。一部のアルゴリズム（たとえばPCA）はオリジナルに比較的近い状態にデータを再構築できる単純な逆変換手続きを持っているが、そのようなものさえ持たないアルゴリズム（たとえばt-SNE）もある。</li>
<li>4. 少なくとも不要な次元を取り除けるので、まったく非線形なものも含め、ほとんどのデータセットの次元を大幅に削減できる。ただし、不要な次元がない（たとえばスイスロールのように）場合には、PCAによる次元削減は失う情報が多すぎる。スイスロールは押しつぶすのではなく、展開したいところだ。</li>
<li>5. データセットによって変わり、1から950までのあらゆる値になる。<br />2つの極端な例を見てみよう。まず、データセットがほとんど完全に1列に並んでいる点から構成されているものとする。この場合、PCAは、95%の分散を維持しながらデータセットを1次元に削減できる。次に、データセットが完全に無作為で1,000のすべての次元でバラバラな点から構成されているものとする。この場合、95%の分散を維持するためには、大まかに言って950次元ほどが必要になるだろう。次数の関数として因子寄与率をプロットすると、データセットの本来の次元をおおよそのところでつかめる。</li>
<li>6. 次の通り。<ul>
<li>通常のPCAはデフォルトだが、データセットがメモリに収まりきらなければ動作しない。</li>
<li>追加学習型PCAはメモリに収まりきらない大規模なデータセットでも使えるが、通常のPCAよりも遅いので、データセットがメモリに収まりきるなら通常のPCAを使った方がよい。</li>
<li>ランダム化PCAは、データセットがメモリに収まり、次元を大幅に削減したいとき、通常のPCAよりも大幅に高速になる。</li>
<li>カーネルPCAは、非線形データセットで役に立つ。</li>
</ul>
</li>
<li>7. 情報をあまり失わずに大幅に次元を削減できれば性能が高いと言ってよい。このような意味での性能は、たとえば、逆変換して再構築誤差を計算すればわかる。ほかの機械学習アルゴリズム（たとえば、ランダムフォレスト分類器）を実行するための前処理として次元削減を行っている場合には、第2のアルゴリズムの性能を測定する方法もある。次元削減によって失われた情報があまり多くなければ、第2のアルゴリズムはもとのデータセットを使ったときに匹敵する性能を発揮するはずだ。</li>
<li>8. しっかりとした意味がある。たとえば、PCAで不要な次元を手っ取り早く大量に取り除いてから、LLEなどの時間のかかる次元削減アルゴリズムを使うことはよくある。この2ステップアプローチは、LLE単独の場合にほぼ匹敵する性能を引き出せるが、処理時間は数分の1になる。</li>
</ul>
<p>問8、問9の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-9"></a>9章：教師なし学習のテクニック</h2>
<ul>
<li>1. クラスタリングは、似ているインスタンス同士をグループにまとめる機械学習の教師なし学習タスクである。類似性の概念は、タスクによって変わる。たとえば、近接している2つのインスタンスが類似していると考えられる場合もあれば、遠く離れていても同じ高密度にパッキングされたグループに属している限り類似していると考えられる場合もある。<br />広く使われているクラスタリングアルゴリズムとしては、K平均法、DBSCAN、凝集クラスタリング、BIRCH、平均値シフト法、アフィニティ伝播法、スペクトラルクラスタリングが挙げられる。</li>
<li>2. データ解析、顧客セグメンテーション、推薦システム、検索エンジン、画像セグメンテーション、半教師あり学習、次元削減、異常検知、新規検知など。</li>
<li>3. 次の通り。<ul>
<li>[1] クラスタ数の関数として慣性（各インスタンスから最近傍重心までの距離の平均二乗距離）のグラフを描き、慣性の低下が止まる曲線の一点「ひじ」を探す。一般にこの点は最適なクラスタ数に近い。</li>
<li>[2] クラスタ数の関数としてシルエットスコアのグラフを描くと、ピークになる点が現れることが多く、最適なクラスタ数はその近くにある。シルエットスコアは、すべてのインスタンスのシルエット係数の平均である。シルエット係数は、クラスタの中心近くにいるときには<span class="equation">\( +1 \)</span>に近く、ほかのクラスタに近いときには<span class="equation">\( -1 \)</span>に近くなる。シルエット図を描けばさらに深い分析ができる。</li>
</ul>
</li>
<li>4. データセットにラベルを付けるのは時間とコストのかかる作業なので、ラベル付きのインスタンスはごくわずかで大多数のインスタンスにはラベルがついていないことがよくある。ラベル伝播とは、ラベル付きインスタンスから類似するラベルなしインスタンスにラベルの一部（または全部）をコピーすることである。<br />こうすると、ラベル付きインスタンスの数が大幅に増え、教師ありアルゴリズムの性能が上がる（半教師あり学習の一形態になる）。<br />すべてのインスタンスに対してK平均法などのクラスタリングアルゴリズムを実行し、個々のクラスでもっとも多いラベルかもっとも代表的なインスタンス（つまり重心にもっとも近いインスタンス）のラベルを調べ、それを同じクラスタのラベルなしインスタンスにコピーしていけば実装できる。</li>
<li>5. 大規模なデータセットに対するスケーラビリティが高いのはK平均法とBIRCH。<br />高密度の領域を探すのはDBSCANと平均シフト法。</li>
<li>6. 能動学習が役に立つのは、ラベルなしインスタンスが多数あるものの、ラベル付けにはコストがかかるときである。<br />このようなとき（非常に多い）、ラベルを付けるインスタンスを無作為に選ぶのではなく、人間の専門家が学習アルゴリズムとやり取りし、アルゴリズムから要求されたときにそのインスタンスのラベルを与える能動学習を行う。よく使われるのは、不確実サンプリングというアプローチである（&lt;chap&gt;{chap09}章ののコラム「能動学習」参照）。</li>
<li>7. <b>異常検知</b>と<b>新規検知</b>は多くの人々に同じ用語として扱われているが、本当は微妙な違いがある。異常検知では、アルゴリズムは外れ値が含まれているかもしれないデータセットで訓練され、一般にその訓練セット内の外れ値や新インスタンス内の外れ値を見つけ出すことが目標になっている。それに対し、新規検知では、アルゴリズムは「クリーン」だとされているデータセットで訓練され、新インスタンス内に含まれる目新しい値を見つけ出すことである。アルゴリズムのなかには異常検知に適したもの（たとえば、アイソレーションフォレスト）と、新規検知に適したもの（たとえば1クラスSVM）がある。</li>
<li>8. 複数のパラメータがわからないガウス分布を混ぜ合わせたものからインスタンスが生成されていると仮定する確率的なモデルである。つまり、データが有限個の楕円形のクラスタにまとめられることを前提としている。ただし、それらの楕円形の形状、サイズ、向き、密度などはまちまちでよい。そして、個々のインスタンスがどのクラスタに含まれるかはわかっていない。<br />密度推定、クラスタリング、異常検知などで役に立つ。</li>
<li>9. 次の通り。<ul>
<li>[1] クラスタ数の関数としてベイズ情報規準（BIC）や赤池情報規準（AIC）をプロットし、BICやAICを最小化するクラスタ数を選ぶ。</li>
<li>[2] 自動的にクラスタ数を選択する混合ベイズガウスモデルを使う。</li>
</ul>
</li>
</ul>
<p>問10から問13の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-10"></a>10章：人工ニューラルネットワークとKerasの初歩</h2>
<ul>
<li>1. TensorFlow Playground（<a href="https://playground.tensorflow.org/" class="link">https://playground.tensorflow.org/</a>）に実際に行って、問題の指示に従って操作してみていただきたい。</li>
<li>2. 次の図はヒントの事実を利用した解の一例である。たとえば、<span class="equation">\( A\oplus B=(A\vee B)\wedge\neg(A\wedge B) \)</span>や<span class="equation">\( A\oplus B=(A\vee B)\wedge(\neg A\vee\wedge B) \)</span>といった事実を利用する別解もある。</li>
</ul>
<div id="mls2_aain01" class="image">
<img src="images/mls2_aain01.png" alt="" />
<p class="caption">
図1: 
</p>
</div>
<ul>
<li>3. 古典的なパーセプトロンは、データセットが線形分離可能なときに限り収束し、クラスに属する確率を推計することができない。それに対し、ロジスティック回帰分類器は、データセットが線形分離可能でなくてもよい解に収束し、クラスに属する確率を出力する。<br />活性化関数をロジスティック活性化関数（複数のニューロンがある場合には、ソフトマックス活性化関数）に変え、勾配降下法（または、交差エントロピーなど、コスト関数を最小化するその他の最適化アルゴリズム）を使って訓練すれば、パーセプトロンはロジスティック回帰分類器と等価になる。</li>
<li>4. 導関数が常に非0で、勾配降下法がいつも勾配を下っていけたから。活性化関数がステップ関数だったときには、勾配というものがないので、勾配降下法は身動きが取れなかった。</li>
<li>5. ステップ関数、ロジスティック（シグモイド）関数、双曲線正接関数、ReLU 関数（&lt;img&gt;{chap10|mls2_1008} 参照）。ELUやReLUのさまざまな変種などのほかの例については&lt;chap&gt;{chap11}を参照。</li>
<li>6. 次の通り。</li>
</ul>
<ul>
<li>訓練バッチサイズを<span class="equation">\( m \)</span>として、<span class="equation">\( m\times 10 \)</span>。</li>
<li>重みベクトルの形は<span class="equation">\( 10\times 50 \)</span>、バイアスベクトルの長さは50。</li>
<li>重みベクトルの形は<span class="equation">\( 50\times 3 \)</span>、バイアスベクトルの長さは3。</li>
<li><span class="equation">\( m\times 3 \)</span></li>
<li><span class="equation">\( \mathbf{Y}^{*}=\text{ReLU}(\text{ReLU}(\mathbf{XW}_h+\mathbf{b}_h)\mathbf{W}_o+\mathbf{b}_o \)</span>)。ReLU関数は、行列内のすべての負数を0にすることを思い出そう。行列にバイアスベクトルを加えるときには、行列のすべての行に加えられる。これを<b>ブロードキャスト</b>（broadcasting）と呼ぶ。</li>
</ul>
<ul>
<li>7. 次の通り。<ul>
<li>電子メール――出力層ニューロンは1個、活性化関数はロジスティック関数。</li>
<li>MNIST――出力層ニューロンは10個、活性化関数はソフトマックス関数（クラスごとに確率を出力できる）。</li>
<li>住宅価格――出力層ニューロンは1個、活性化関数は使わない<a id="fnb-f3" href="#fn-f3" class="noteref" epub:type="noteref">*3</a>。</li>
</ul>
</li>
</ul>
<ul>
<li>8. バックプロパゲーション（誤差逆伝播法）は、人工ニューラルネットワークの訓練に使われるテクニックである。まず、すべてのモデルパラメータ（すべての重みとバイアス）についてコスト関数の勾配を計算し、次にそれらの勾配を使って勾配降下ステップを行う。この逆進（バックプロパゲーション）ステップは、一般に多くの訓練バッチを使って、モデルパラメータがコスト関数を最小化する値に収束するまで、数千から数百万回も実行される。<br />バックプロパゲーションは、勾配を計算するために、リバースモード自動微分を使う（バックプロパゲーションが考え出された当時は、リバースモード自動微分はそのような名前では呼ばれていなかったし、バックプロパゲーションは何度も別々に発明されているが）。リバースモード自動微分は、計算グラフに沿ってフォワードパスを実行し、現在の訓練バッチに対する各ノードの値を計算してから、すべての勾配を一度に計算してリバースパスを実行する（詳細は&lt;chap&gt;{appd}を参照）。<br />では両者の違いは何か。バックプロパゲーションは、複数のバックプロパゲーションステップを使って人工ニューラルネットワークを訓練するプロセス全体を指す。個々のバックプロパゲーションステップは、勾配を計算し、それを使って勾配降下ステップを実行する。それに対し、リバースモード自動微分は、単純に勾配を効率よく計算するためのテクニックであり、バックプロパゲーションがたまたま使っているだけである。</li>
<li>9. 隠れ層の数、隠れ層のニューロンの数、個々の隠れ層と出力層で使われる活性化関数<a id="fnb-f4" href="#fn-f4" class="noteref" epub:type="noteref">*4</a>。一般に、隠れ層の活性化関数のデフォルトとしてはReLU（またはその変種。&lt;chap&gt;{chap11}参照）がよい。出力層では、二項分類ならロジスティック関数、多クラス分類ならソフトマックス関数、回帰なら活性化関数なしがよい。<br />MLPが訓練データを過学習している場合には、隠れ層の数を減らしたり、隠れ層あたりのニューロン数を減らすとよい。</li>
<li>10. <a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブック参照。</li>
</ul>
<div class="footnote" epub:type="footnote" id="fn-f3"><p class="footnote">[*3] 予測しようとしている値が何桁も異なる値になり得る場合には、ターゲット値を直接予測するのではなく、ターゲット値の自然対数を予測するとよい。ニューラルネットワークの出力だけネイピア数を累乗すれば、ターゲット値が得られる（<span class="equation">\( \exp(\log v)= v \)</span>なので）。</p></div>
<div class="footnote" epub:type="footnote" id="fn-f4"><p class="footnote">[*4] &lt;chap&gt;{chap11}で取り上げるさまざまなテクニックは、重みの初期化タイプ、活性化関数のハイパーパラメータ（たとえば、leakyReLUのリーク量）、勾配クリッピングのしきい値、オプティマイザのタイプとそのハイパーパラメータ（たとえば、<code class="tt">MomentumOptimizer</code>を使うときの運動量ハイパーパラメータ）、各層の正則化のタイプ、正則化ハイパーパラメータ（たとえば、ドロップアウトを使うときのドロップアウト率）などの新たなハイパーパラメータを導入する。</p></div>

<h2><a id="h-11"></a>11章：深層ニューラルネットワークの訓練</h2>
<ul>
<li>1. よくない。<br />重みの初期値はすべて独立にサンプリングすべきで、同じ初期値にまとめてしまってはよくない。重みを無作為にサンプリングすることには重要な目的があり、その1つは対称性を破ることだ。たとえ0以外であってもすべての重みの初期値が同じだと、バックプロパゲーションでも破れない対称性が生まれてしまう。具体的に言うと、ある層のすべてのニューロンがいつも同じ重みになってしまう。これでは、層ごとに1つのニューロンしかないのと同じになり、遅くなってしまう。そして、そのような構成では、よい解に収束することはほとんど不可能になる。</li>
<li>2. まったく問題ない。<br />重みと同じような初期化を好む人もいるが、それはそれでよい。どちらにしても大差はない。</li>
<li>3. 次の通り。<ul>
<li>負数を返すことができるので、1つの層に属するすべてのニューロンの平均が、ReLU関数（負数を返さない）を使ったときよりも、0に近くなる。これは、勾配消失問題の緩和に役立つ。</li>
<li>必ず0以外の導関数を持つため、dying ReLU の問題を避けられる。</li>
<li>条件が満たされれば、つまり、モデルがシーケンシャルで、重みがルカン初期値で初期化され、入力が標準化され、互換性のない層や正則化（ドロップアウトや<span class="equation">\( \ell_1 \)</span>正則化など）が使われていなければ、SELU活性化関数を使うとモデルが自己正規化され、勾配消失／爆発問題が解決される。</li>
</ul>
</li>
</ul>
<ul>
<li>4. 次の通り。<ul>
<li><b>SELU</b>はよいデフォルトになる。</li>
<li>ニューラルネットワークをできる限り高速に実行したい場合は、SELUではなく、何らかの<b>leaky ReLU</b>を使った方がよい（たとえば、デフォルトのハイパーパラメータ値を使った単純なleaky ReLU）。</li>
<li><b>ReLU</b>は単純なので多くの人々が好んで使っているが、一般にSELUやleaky ReLUよりも性能が低い。しかし、ReLUの正確な0を出力できるところが役に立つ場合がある（たとえば、&lt;chap&gt;{chap17}を参照）。また、最適化実装やハードウェアアクセラレーションによって高速化されている場合がある。</li>
<li><b>双曲線正接関数</b>（tanh）は、<span class="equation">\( -1 \)</span>から1までの値を出力しなければならないときには、出力層で役に立つことがあるが、現在では、隠れ層ではまず使われない（再帰型ネットワークを除く）。</li>
<li><b>ロジスティック関数</b>も、確率を推計しなければならないとき（たとえば二項分類）には出力層で使われるが、隠れ層ではまず使われない（ただし、変分オートエンコーダのコーディング層などの例外がある。&lt;chap&gt;{chap17}参照）。</li>
<li><b>ソフトマックス関数</b>は、相互排他的なクラスに属する確率を出力するために出力層で使われるが、隠れ層ではまず使われない。</li>
</ul>
</li>
</ul>
<ul>
<li>5. アルゴリズムが高速化し、おおよそ全体の最小値の方に向かっていくが、その運動量の強さのために最小値を通り過ぎてしまう。その後、スピードは遅くなり、逆に最小値の方に戻り始め、再び加速し、再び最小値を通り過ぎる。これを繰り返す。収束するまでにこのような振動を何度も繰り返すため、全体としては、<code class="tt">momentum</code>を小さくしたときよりも収束までにかかる時間が長くなる。</li>
<li>6. 次の通り。<ul>
<li>モデルを普通に訓練して重みが小さいところを0にする。</li>
<li>訓練中にオプティマイザを疎なモデルの方に誘導する<span class="equation">\( \ell_1 \)</span>正則化を使う。</li>
<li>TF-MOTを使う。</li>
</ul>
</li>
</ul>
<ul>
<li>7. ドロップアウトは訓練の速度を遅らせる。一般に約2倍の時間がかかるようになる。<br />しかし、訓練時以外はオンにされないので、推論の速度には影響を与えない。<br />MCドロップアウトは、訓練時にはドロップアウトと同じだが、推論中もアクティブなので、個々の推論が少し遅くなる。それよりも重要なことだが、MCドロップアウトを使うときには予測性能を上げるために推論を10回以上実行するのが普通なので、その分予測が10倍以上遅くなる。</li>
</ul>
<p>問8の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-12"></a>12章：TensorFlowで作るカスタムモデルとその訓練</h2>
<ul>
<li>1. 次の通り。<ul>
<li>TensorFlowは数値演算用のオープンソースライブラリで、特に大規模な機械学習に適しており、この用途で性能が上がるように調整されている。</li>
<li>核の部分はNumPyと似ているが、GPU、分散コンピューティング、計算グラフの分析と最適化（計算グラフの形式には可搬性があり、TensorFlowモデルを訓練した環境とは別の本番環境でモデルを実行できる）、リバースモード自動微分に基づく最適化API、tf.keras、tf.data、tf.image、tf.signalなどの強力なAPIをサポートしている。</li>
<li>TensorFlow以外で広く使われている深層学習ライブラリとしては、PyTorch、MXNet、Microsoft Cognitive Toolkit、Theano、Caffe2、Chainerがある。</li>
</ul>
</li>
</ul>
<ul>
<li>2. TensorFlowはNumPyの機能の大半を提供しているが、次のような理由からNumPyの代わりにドロップインすることはできない。<ul>
<li>[1] 関数名が必ずしも同じではない（たとえば、<code class="tt">tf.reduce_sum()</code>と<code class="tt">np.sum()</code>など）。</li>
<li>[2] 一部の関数は挙動が同じではない（たとえば、<code class="tt">tf.transpose()</code>はテンソルを転置したコピーを作るが、NumPyの<code class="tt">T</code>属性は転置したビューを作るだけで、データをコピーしない）。</li>
<li>[3]NumPyの配列はミュータブルだが、TensorFlowのテンソルはイミュータブルである（ただし、ミュータブルなオブジェクトが必要なら、<code class="tt">tf.Variable</code>を使える）。</li>
</ul>
</li>
</ul>
<ul>
<li>3. <code class="tt">tf.range(10)</code>と<code class="tt">tf.constant(np.arange(10))</code>は、どちらも0から9までの整数を格納する1次元テンソルを返す。しかし、前者が32ビット整数を使うのに対し、後者は64ビット整数を使う。TensorFlowはデフォルトが32ビットであるのに対し、NumPyはデフォルトで64ビットである。</li>
<li>4. 疎テンソル、テンソル配列、不調和テンソル、キュー、文字列テンソル、集合。<br />最後の2種類は実際には通常のテンソルで表現されているが、TensorFlowはこれらを操作するための特別な関数を提供している（<code class="tt">tf.strings</code>と<code class="tt">tf.sets</code>）。</li>
<li>5. 一般的には、通常のPython関数としてカスタム損失関数を定義すればよい。しかし、カスタム損失関数が何らかのハイパーパラメータ（または状態）をサポートしなければならない場合には、<code class="tt">keras.losses.Loss</code>をサブクラス化して<code class="tt">__init__()</code>、<code class="tt">call()</code>メソッドを実装する。モデルとともに損失関数のハイパーパラメータも保存したい場合には、<code class="tt">get_config()</code>メソッドも実装しなければならない。</li>
<li>6. 損失関数と同様に、ほとんどの指標は通常のPython関数で定義できる。しかし、カスタム指標が何らかのハイパーパラメータ（または状態）をサポートしなければならない場合には、<code class="tt">keras.metrics.Metric</code>クラスをサブクラス化する。さらに、エポックに含まれるすべてのバッチの指標を平均しても、エポック全体の指標にならない場合がある（たとえば、適合率、再現率など）。そのような場合には、<code class="tt">keras.metrics.Metric</code>クラスをサブクラス化し、<code class="tt">__init__()</code>、<code class="tt">update_state()</code>、<code class="tt">result()</code>を実装してエポックが終わるまでその時点までの指標を追跡、管理する必要がある。また、すべての変数を0.0にリセットする以外の処理が必要なら、<code class="tt">reset_states()</code>も実装しなければならない。そして、モデルとともに指標の状態情報を保存したい場合には、<code class="tt">get_config()</code>メソッドも実装しなければならない。</li>
<li>7. モデル自体（つまり、訓練の対象となるオブジェクト）とモデルの内部コンポーネント（レイヤや複数のレイヤをまとめた再利用可能なブロック）を区別しなければならない。モデル自体を作るなら<code class="tt">keras.models.Model</code>クラス、レイヤを作るなら<code class="tt">keras.models.Layer</code>クラスををサブクラス化する。</li>
<li>8. カスタム訓練ループの独自実装はかなり高度な作業なので、どうしても必要なとき以外は避けるべきだ。Kerasは、カスタム訓練ループを書かなくても訓練をカスタマイズできるツールとして、コールバック、カスタム正則化器、カスタム制約、カスタム損失関数などを提供している。これらでカスタマイズできるときにはこれらを使い、カスタム訓練ループを作ろうなどとは考えない方がよい。カスタム訓練ループの方が、実装ミスを起こしやすく、書いたコードを再利用しにくい。<br />しかし、ワイド・アンド・ディープ論文（<a href="https://homl.info/widedeep" class="link">https://homl.info/widedeep</a>）のように、ニューラルネットワークの異なる部分で異なるオプティマイザを使いたい場合などは、どうしてもカスタム訓練ループを書くことが必要になる。訓練の仕組みを正確に理解したいときやデバッグを目的とするときもカスタム訓練ループが役に立つ。</li>
<li>9. カスタムKerasコンポーネントは、TF関数に変換できなければならない。つまり、できる限りTensorFLowオペレーションだけを行い、「12.4.2 TF関数のルール」に書かれているすべてのルールを守っていなければならない。<br />カスタムコンポーネントにどうしても一般的なPythonコードを入れなければならないときには、<code class="tt">tf.py_function()</code>でラップする（ただし、これをすると処理速度が落ち、モデルの可搬性が下がる）か、カスタムレイヤやモデルを作るときに<code class="tt">dynamic=True</code>を指定する（または、モデルの<code class="tt">compile()</code>メソッドを呼び出すときに、<code class="tt">run_eagerly=True</code>を指定する）。</li>
<li>10. TF関数を作るときに守らなければならないルールは、「12.4.2 TF関数のルール」を参照のこと。</li>
<li>11. 次の通り。<ul>
<li>[1] ダイナミックモデルが必要なとき。<ul>
<li>デバッグ用。任意のカスタムコンポーネントをTF関数にコンパイルでき、任意のPythonデバッガデコードをデバッグできる。</li>
<li>外部ライブラリ呼び出しなど、任意のPythonコードをモデル（または訓練コード）に取り込みたいとき。</li>
</ul>
</li>
<li>[2] 作り方。モデルを作るときに<code class="tt">dynamic=True</code>を指定するか、モデルの<code class="tt">compile()</code>メソッドを呼び出すときに<code class="tt">run_eagerly=True</code>を指定する。</li>
<li>[3] ダイナミックモデルを避ける理由。<ul>
<li>モデルをダイナミックにすると、KerasはTensorFlowのグラフ機能を使えなくなり、訓練、推論の速度が落ちる。</li>
<li>計算グラフをエクスポートできなくなる場合があり、モデルの可搬性が下がる。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>演習問題12、13の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-13"></a>13章：TensorFlowによるデータのロードと前処理</h2>
<ul>
<li>1. 大規模なデータセットを効率よくインジェスト、前処理するのは、技術的に複雑な課題だが、データAPIはそれを簡単にしてくれるから。<br />データAPIには、さまざまなソース（テキスト、バイナリファイルなど）からのデータのロード、複数のソースからのデータの並列読み出し、変換、レコードのインターリーブ、データのシャッフル、バッチへの分割、プリフェッチなどの多彩な機能が含まれている。</li>
<li>2. シャッフルバッファを使った細かいレベルでのシャッフルの前に、粗いレベルでシャッフルできること。1台のマシンには収まりきらない巨大データセットを処理できるようになること。1個の巨大ファイルを処理するよりも、無数の小ファイルを操作した方が仕事が単純になること（たとえば、データを複数のサブセットに分割しやすい）。データが複数のサーバーの複数のファイルに分散している場合、複数のサーバーから同時に複数のファイルをダウンロードでき、帯域幅を効率よく使えること。</li>
<li>3. TensorBoardを使ってプロファイリングデータを可視化すればよい。GPUがフル稼働していなければ、入力パイプラインがボトルネックになっている可能性がある。この問題は、マルチスレッドを使ってデータを並列に読み出し、前処理するとともに、数バッチをプリフェッチすれば対処できる。それでも訓練中のGPUの稼働率が100%にならない場合には、前処理コードを最適化すべきだ。複数のTFRecordファイルにデータセットを保存し、必要なら前処理の一部を事前に実行して訓練中にその場その場で前処理をしなくても済むようにしよう（これに関してはTF Transformが役に立つ）。必要なら、CPUやRAMをもっと積んだマシンを使い、GPUの帯域幅を最高に引き上げるようにすべきだ。</li>
<li>4. どんなバイナリデータでも間違いなく保存できる。TFRecordファイルは、任意のバイナリレコードのシーケンスから構成されている。<br />しかし、実際のTFRecordファイルの大半は、シリアライズされたプロトコルバッファのシーケンスを格納している。こうすると、プラットフォームや言語の違いを越えて簡単に読み出せるとか、あとで下位互換性を維持しながら定義を更新できるといったプロトコルバッファの利点を活かせる。</li>
<li>5. <code class="tt">Example</code> protobuf形式には、独自形式を定義しなくても、TensorFlowがパースのためのオペレーション（<code class="tt">tf.io.parse*example()</code>関数群）を提供しているという利点がある。<code class="tt">Example</code>には、ほとんどのデータセットのインスタンスを表現できるだけの柔軟性がある。<br />しかし、<code class="tt">Example</code>では目の前のユースケースに対応できない場合には、独自プロトコルバファを定義し、<code class="tt">protoc</code>でコンパイルする（protobuf記述子をエキスポートするために<code class="tt">--descriptor_set_out</code>、<code class="tt">--include_imports</code>引数を設定する）。そして<code class="tt">tf.io.decode_proto()</code>関数を使ってシリアライズされたprotobufをパースする（具体例についてはJupyterノートブックの&quot;Custom protobuf&quot;を参照のこと）。この方法は<code class="tt">Example</code>を使う方法よりも複雑で、モデルとともにデスクリプタもデプロイしなければならないが、できることに間違いはない。</li>
<li>6. 訓練スクリプトがTFRecordファイルをダウンロードしなければならない場合。圧縮すれば、ファイルが小さくなり、ダウンロードにかかる時間を短縮できる。<br />しかし、ファイルが訓練スクリプトと同じマシンに置かれるときには、復号のためにCPUを浪費するのを避けるために、一般に圧縮をオフにした方がよい。</li>
<li>7. それぞれの方法の長所、短所をまとめておこう。<ul>
<li><b>データファイル作成時の前処理</b><ul>
<li><b>長所</b>：<ul>
<li>その場で前処理を実行しなくて済むので、訓練スクリプトの実行速度が上がる。</li>
<li>前処理後のデータがもとのデータよりもずっと小さくなる場合があり、そのときには記憶スペースが節約でき、ダウンロードにかかる時間が短縮される。</li>
<li>前処理したデータが実体化され、内容をチェックしたりアーカイブ化したりするときに便利である。</li>
</ul>
</li>
<li><b>短所</b>：<ul>
<li>前処理したデータセットをいちいち生成しなければならないので、さまざまな前処理ロジックを試しにくい。</li>
<li>データ拡張したいときに、データセットのさまざまな変種を実体化しなければならないので、大量のディスクスペースを消費し、ファイル生成のために時間がかかる。</li>
<li>訓練済みモデルは前処理されたデータが送られてくることを想定しているので、アプリケーションのモデルを呼び出す部分の前に前処理コードを追加しなければならない。</li>
</ul>
</li>
</ul>
</li>
<li><b>tf.dataパイプラインによる前処理</b><ul>
<li><b>長所</b>：<ul>
<li>前処理ロジックに手を入れたりデータ拡張したりするのがほかの方法よりもずっと簡単。</li>
<li>tf.dataを使うと、非常に処理効率が高い前処理パイプラインを簡単に構築できる（たとえば、マルチスレッドやプリフェッチの利用）。</li>
</ul>
</li>
<li><b>短所</b>：<ul>
<li>訓練にかかる時間が長くなる。</li>
<li>個々の訓練インスタンスがエポックごとに前処理される。データファイルを作るときに前処理していれば、1度だけで済む。</li>
<li>この方法でも訓練されたモデルは前処理されたデータを必要とする。</li>
</ul>
</li>
</ul>
</li>
<li><b>モデルに前処理層を追加する方法</b><ul>
<li><b>長所</b>：<ul>
<li>訓練、予測の両方で使える前処理コードを1度書くだけで済む。</li>
<li>さまざまなプラットフォームにモデルをデプロイしなければならない場合でも、前処理コードを何度も書かなくて済む。</li>
<li>前処理ロジックがモデルの一部になるので、モデルにとって不適切な前処理ロジックを使うリスクがなくなる。</li>
</ul>
</li>
<li><b>短所</b>：<ul>
<li>前処理によって訓練にかかる時間が長くなり、個々の訓練インスタンスがエポックごとに1度ずつ前処理されるようになる。</li>
<li>デフォルトで現在のバッチのための前処理がGPUで実行されることになる（CPU上で並列に前処理してプリフェッチしたときのメリットが得られない）。ただし、近くリリースされるKerasの前処理層は、前処理層から前処理オペレーションを取り出し、tf.dataパイプラインの一部として実行できるため、CPUとプリフェッチによるマルチスレッド実行のメリットが得られる。</li>
</ul>
</li>
</ul>
</li>
<li><b>TF Transformを使った前処理</b><ul>
<li><b>長所</b>：<ul>
<li>前処理されたデータが実体化される。</li>
<li>各インスタンスの前処理が1度だけになる（訓練にかかる時間が短縮される）。</li>
<li>前処理層が自動生成されるため、前処理コードは1度書くだけでよい。</li>
</ul>
</li>
<li><b>短所</b>：<ul>
<li>このツールの使い方を学ばなければならない。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>8. 次の通り。<ul>
<li><b>カテゴリ特徴量</b><ul>
<li>映画の評価「だめ」、「普通」、「いい」のように自然な順序があるものの場合、その順序に合わせて番号を振るのがもっとも簡単である。その自然な順序に従ってカテゴリを分類し、<b>カテゴリをランクに変換</b>する。たとえば、「だめ」が0、「普通」が1、「いい」が2のように。</li>
<li>そのような自然な順序がない大半のカテゴリ特徴量では、<b>ワンホットエンコーディング</b>か<b>埋め込み</b>（カテゴリが多い場合）を使う。</li>
</ul>
</li>
<li><b>テキスト特徴量</b><ul>
<li><b>バッグオブワーズ</b>：含まれている単語の出現回数を示すベクトルで文を表現する。頻出語にはたいてい大した意味はないので、<b>tf-idf</b>（単語の出現頻度-逆文書頻度）で重みを減らす。語数ではなく、<span class="equation">\( n \)</span><b>グラム</b>（n-gram、<span class="equation">\( n \)</span>個の連続した単語のシーケンス）を数えることも多い。</li>
<li><b>単語埋め込み</b>：おそらく訓練済みのモデルを再利用することになる。単語ではなく、文字や単語の一部（たとえば、smartestをsmartとestに分割する）の埋め込みを作る方法もある。&lt;chap&gt;{chap16}参照。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>問9、問10の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-14"></a>14章：畳み込みニューラルネットワークを使った深層コンピュータビジョン</h2>
<ul>
<li>1. 次の通り。<ul>
<li>連続する層が部分的にしか接続されず、重さを積極的に再利用するので、全結合のDNNよりもパラメータの数が大幅に少なく、訓練をスピードアップでき、過学習のリスクが軽減され、必要な訓練データが大幅に減る。</li>
<li>CNNは、特定の特徴量を検出できるカーネルを学習すると、その特徴量が画像のどこにあっても検出できる。それに対し、DNNはある位置で特徴量を学習しても、その位置にある特徴量しか検出できない。画像には反復して現れる特徴量が含まれるのが普通なので、分類などの画像処理タスクでは、CNNの方がDNNよりも少ない訓練データで高い汎化性能が得られる。</li>
<li>DNNは、ピクセルがどのように組織されているかについての事前知識がなく、近隣のピクセルが近くにあることを知らないが、CNNは、アーキテクチャにこのような事前知識が組み込まれている。一般に、下位層はイメージの小さな領域に含まれる特徴量を識別し、上位層は下位レベルの特徴量を組み合わせて大きな特徴量を認識する。自然にあるほとんどのイメージでは、これがうまく機能するため、CNNは最初の時点でDNNよりも有利である。</li>
</ul>
</li>
</ul>
<ul>
<li>2. 次の通り。<ul>
<li>a. 次の通り。<ul>
<li>最初の畳み込み層のカーネルは<span class="equation">\( 3\times 3 \)</span>で、入力は3チャネル（赤、緑、青）なので、個々の特徴量マップは<span class="equation">\( 3\times 3\times 3=27 \)</span>個の重みと1個のバイアス項で28個のパラメータを持つ。100個の特徴量マップを出力するので、この層は<span class="equation">\( 28\times 100=2,800 \)</span>個のパラメータを持つ。</li>
<li>第2の畳み込み層のカーネルも<span class="equation">\( 3\times 3 \)</span>で、入力は前の層が出力した100個の特徴量マップなので、個々の特徴量マップは<span class="equation">\( 3\times 3\times 100=900 \)</span>個の重みと1個のバイアス項を持つ。200個の特徴量マップを出力するので、この層は<span class="equation">\( 901\times 200=180,200 \)</span>個のパラメータを持つ。</li>
<li>第3の畳み込み層もカーネルは<span class="equation">\( 3\times 3 \)</span>で、入力は前の層が出力した200個の特徴量マップなので、個々の特徴量マップは<span class="equation">\( 3\times 3\times 200=1,800 \)</span>個の重みと1個のバイアス項を持つ。400個の特徴量マップを出力するので、この層は<span class="equation">\( 1,801\times 400=720,400 \)</span>個のパラメータを持つ。</li>
<li>以上を合計して、このCNNは<span class="equation">\( 2,800+180,200+720,400=903,400 \)</span>個のパラメータを持つ。</li>
</ul>
</li>
<li>b. まず、各層の特徴量マップのサイズを計算する。ストライドが2で<code class="tt">&quot;same&quot;</code>パディングを使っているので、各層で特徴量マップの幅と高さは2で割られる（必要に応じて切り上げられる）。入力チャネルが<span class="equation">\( 200\times 300 \)</span>ピクセルなので、第1層の特徴量マップは<span class="equation">\( 100\times 150 \)</span>ピクセル、第2層の特徴量マップは<span class="equation">\( 50\times 75 \)</span>ピクセル、第3層の特徴量マップは<span class="equation">\( 25\times 38 \)</span>ピクセルになる。<br />32ビットは4バイトで、最初の畳み込み層は100個の特徴量マップを出力するので、第1層が必要とするメモリは、<span class="equation">\( 4\times 100\times 150\times 100=600 \)</span>万バイト（6MB）になる。第2層は、<span class="equation">\( 4\times 50\times 75\times 200=300 \)</span>万バイト（3MB）、第3層は<span class="equation">\( 4\times 25\times 38\times 400=1,520,000 \)</span>バイト（約1.5MB）となる。<br />ただし、1つの層の計算が終わると、その前の層が占有していたメモリは開放できるので、すべてが適切に最適化されていれば、<span class="equation">\( 6+3=9 \)</span>MBのRAMがあれば足りる（第2層の計算が終わったとき、第1層が占有していたメモリはまだ開放されていないので）。<br />しかし、特徴量マップだけでなく、CNNのパラメータが占有するメモリのサイズも追加しなければならない。先ほど計算したように、パラメータの数は903,400個で、それぞれ4バイトを消費するので、全部で3,613,600バイト（約3.6MB）になる。そのため、必要とされるRAMは、合計で（少なくとも）12,613,600バイト（約12.6MB）である。</li>
<li>c. 訓練中のTensorFlowはバックプロパゲーションを使うため、後退パスが始まるまで前進パスで計算したすべての値を残しておかなければならない。そのため、1つのインスタンスのためにすべての層で必要になるRAMの合計量を計算した上でそれを50倍しなければならない。先ほど計算したように、各インスタンスのために3つの層がそれぞれ6、3、1.5MBあり、合計で10.5MBが必要なので、50インスタンスで525MBとなる。これに入力イメージが必要とする<span class="equation">\( 50\times 40\times 200\times 300\times 3=3,600 \)</span>万バイト（36MB）とモデルパラメータの約3.6MBを加える。バックプロパゲーションで必要なRAMもあるが、後退パスで層を下がっていく過程で少しずつ開放できるので無視してよい。そこで、<span class="equation">\( 525+36+3.6=564.6 \)</span>MBとなる。楽観的に考えたときの最低限でこれだけの容量が必要になる。</li>
</ul>
</li>
</ul>
<ul>
<li>3. もっと多くのRAMを積んでいるGPUを買ってくる場合を除き、次の5つである。<ul>
<li>ミニバッチサイズを小さくする。</li>
<li>1つ以上の層でストライドを大きくして次元削減する。</li>
<li>1つ以上の層を取り除く。</li>
<li>32ビット浮動小数点数ではなく、16ビット浮動小数点数を使う。</li>
<li>CNNを複数のデバイスで分散処理する。</li>
</ul>
</li>
</ul>
<ul>
<li>4. 最大値プーリング層はパラメータをいっさい持たないが、畳み込み層はかなりの数のパラメータを持つ（今までの問題を参照）こと。</li>
<li>5. LRN層は、特に強く活性化しているニューロンによって近隣の特徴量マップの同じ位置のニューロンが活性化されることを禁止する。これにより、異なる特徴量マップは専門分化して、否応なく広い範囲の特徴量を探るようになる。LRN層は、一般に上位層が部品として使う下位レベルの特徴量を多く準備したい下位層で使われる。</li>
<li>6. 次の通り。<ul>
<li><b>AlexNet</b>は、LeNet-5と比べて①ずっと大規模で深く、②個々の畳み込み層の上にプーリング層を重ねるのではなく、畳み込み層を直接積み上げたことが新しい。</li>
<li><b>GoogLeNet</b>は、<b>インセプションモジュール</b>（inception module）の導入により、従来のCNNアーキテクチャよりも少ないパラメータで従来よりもずっと深いニューラルネットワークを作れるようにした。</li>
<li><b>ResNet</b>は、スキップ接続を導入し、100層を越えるネットワークを作れるようにした。単純で一貫していることもイノベーティブだと言ってよいだろう。</li>
<li><b>Xception</b>は、<b>深度分離可能な畳み込み層</b>（depthwise separable convolutional layer）を導入して、空間パターンと深度（交差チャネル）パターンを別々に探すようにした。</li>
<li><b>SENet</b>は、インセプションネットワークのすべてのインセプションモジュール、ResNetのすべての残差ユニットのうしろに<b>SEブロック</b>（2層の全結合層）を追加して、特徴量マップの相対的な重要性を調整した。</li>
</ul>
</li>
</ul>
<ul>
<li>7. 次の通り。<ul>
<li>FCNは、畳み込み層とプーリング層だけで構成されるニューラルネットワークで、幅と高さがまちまちな画像（少なくとも最小限以上のもの）を効率よく処理できる。画像を1度見るだけで済む（画像のさまざまな部分で複数回CNNを実行する必要がない）ので、物体検知やセマンティックセグメンテーションで特に役に立つ。</li>
<li>最上位に全結合層が乗っているCNNがある場合、その全結合層を畳み込み層に置き換えればFCNになる。①カーネルサイズが入力サイズと等しく、②全結合層のニューロンと同数のフィルタを持ち、③<code class="tt">&quot;valid&quot;</code>パディングを使った畳み込み層は、最下位の全結合層の代わりとして使える。</li>
</ul>
</li>
</ul>
<p>一般にストライド数は1にすべきだが、必要なら大きくしてよい。活性化関数は全結合層と同じものにする。最下位層以外の全結合層も、<span class="equation">\( 1\times 1 \)</span>フィルタを使うことを除けば同じようにして変換できる。全結合層の重み行列の形を適切に変えれば、訓練済みのCNNをこのようにして変換できる。</p>
<ul>
<li>8. CNNでは、信号が各層、特にプーリング層とストライドが2以上の畳み込み層を通過すると、空間情報が大きく失われていくことである。個々のピクセルが属するクラスを正確に予測するためには、失われた空間情報を復元する必要がある。</li>
</ul>
<p>問9から問11の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-15"></a>15章：RNNとCNNを使ったシーケンスの処理</h2>
<ul>
<li>1. 次の通り。<ul>
<li><b>シーケンス・ツー・シーケンスRNN</b>：天気（その他あらゆる時系列データ）の予測、機械翻訳（エンコーダ－デコーダアーキテクチャを使う）、ビデオのタイトル設定、音声のテキスト起こし、音楽生成（その他のシーケンス生成）、曲の和音の識別。</li>
<li><b>シーケンス・ツー・ベクトルRNN</b>：音楽サンプルのジャンルによる分類、書評の感情分析、脳内インプラントの読み出しからの失語症患者が考えている単語の予測、映画鑑賞歴に基づくユーザーが映画を見たいと思う確率の予測（これは、推薦システムの協調フィルタリング：collaborative filteringのさまざまな実装の一例である）。</li>
<li><b>ベクトル・ツー・シーケンスRNN</b>：画像のタイトル設定、現在再生中のアーティストの埋め込みに基づく音楽再生リストの作成、一連のパラメータに基づくメロディの生成、写真（たとえば、自動運転車のカメラの動画フレーム）内の歩行者の検出。</li>
</ul>
</li>
</ul>
<ul>
<li>2. RNN層の入力は3次元で、第1次元はバッチサイズ、第2次元は時間（タイムステップ）、第3次元は各タイムステップでの入力（サイズはタイムステップごとの入力特徴量の数）を表す。<br />たとえば、各タイムステップで2個の入力がある10のタイムステップから構成される5個の時系列データのバッチがあるとき、入力の形は[5, 10, 2]になる。<br />出力も3次元で、最初の2次元は入力と同じだが、最後の次元はニューロン数である。<br />たとえば、32個のニューロンで上記のバッチを出力するRNN層の出力の形は、[5, 10, 32]になる。</li>
<li>3. Kerasで深層シーケンス・ツー・シーケンスRNNを作るときには、すべてのRNN層で<code class="tt">return_sequences=True</code>を指定しなければならない。<br />深層シーケンス・ツー・ベクトルRNNを作るときには、最上位のRNN層を除くすべてのRNN層で<code class="tt">return_sequences=True</code>を指定しなければならない。最上位層には<code class="tt">return_</code><code class="tt">sequences=False</code>を指定するか、何も指定しない（この引数のデフォルトは<code class="tt">False</code>なので）。</li>
<li>4. もっとも単純なRNNアーキテクチャは、RNN層を積み上げ（最上位のRNN層以外には<code class="tt">return_sequences=True</code>を指定する）、出力層では7個のニューロンを使う。このモデルは、時系列データから無作為な範囲を切り出してきて訓練することができる（たとえば、無作為な30日分のシーケンスを入力とし、そのあとの7日分の値を格納するベクトルをターゲットとする）。これはシーケンス・ツー・ベクトルRNNである。<br />すべてのRNN層で<code class="tt">return_sequences=True</code>を指定してシーケンス・ツー・シーケンスRNNを作る方法もある。このモデルは、時系列データから無作為な範囲を切り出し、それに続いてターゲットとして入力と同じ長さのシーケンスを付ければ訓練できる。個々のターゲットシーケンスは、タイムステップあたり7個の値を持たなければならない（たとえば、タイプステップ<span class="equation">\( t \)</span>なら、ターゲットはタイムステップ<span class="equation">\( t+1 \)</span>から<span class="equation">\( t+7 \)</span>までの値を格納するベクトルでなければならない。</li>
<li>5. 長いシーケンスを処理しようとすると悪化していく大きな問題が2つある。<ul>
<li>a. 不安定な勾配（爆発または消失）――a.学習率を小さくし、b.双曲線正接などの飽和する活性化関数を使い（双曲線正接はデフォルトになっている）、c.各タイムステップで購買クリッピング、層正規化、ドロップアウトを使うといった方法で緩和する。</li>
<li>b. 記憶が短期間に限られること――<code class="tt">LSTM</code>層や<code class="tt">GRU</code>層を使って対処する（両者とも、不安定な勾配問題にも効果がある）。</li>
</ul>
</li>
</ul>
<ul>
<li>6. LSTMセルのアーキテクチャは複雑な感じがするが、背後に潜む論理が理解できれば実際にはそれほど難しいものではない。<br />セルは、短期状態ベクトルと長期状態ベクトルを持つ。単純なRNNセルと3個のゲートには、タイムステップごとに入力と直前の短期状態が与えられる。忘却ゲートは長期状態から取り除くべき情報を判断し、入力ゲートは単純なRNNセルの出力のどの部分を長期状態に追加するかを決め、出力ゲートは長期状態のなかのどの部分をこのタイムステップで出力するか（双曲線正接活性化関数を通してから）を決める。新しい短期状態は、セルの出力と等しい。&lt;img&gt;{chap15|mls2_1509}参照。</li>
<li>7. RNN層は基本的にシーケンシャルだ。タイムステップ<span class="equation">\( t \)</span>における出力を計算するためには、まずそれまでのすべてのタイムステップの出力を計算しなければならないため、並列化できない。一方、1次元畳み込み層は、タイムステップ間で状態を受け渡したりしないので、並列化できる。つまり、1次元畳み込み層は記憶を持たない。ある特定のタイムステップでの出力は、過去の値を知らなくても、入力の一部の値だけがわかれば計算できる。しかも、1次元畳み込み層は再帰的ではないため、不安定な勾配にもあまり悩まされない。たとえば、RNNで一時的に解像度を削減（ダウンサンプリング）し、それによってRNN層が長期的なパターンを検出するのを支援したりしたい場合、RNNに1つ以上の1次元畳み込み層を入れると役に立つ。実際、たとえばWaveNetアーキテクチャを構築するなどの方法を使えば、1次元畳み込み層だけでRNN層と同じ機能を持つものを作れる。</li>
<li>8. 画像としてのコンテンツに基づいて動画を分類するには、たとえば、1秒に1フレームずつ取り出し、同じ畳み込みニューラルネットワーク（訓練済みのXceptionモデルなど。データセットが大きくなければ凍結しておく）でそれらのフレームをすべて処理し、CNNからの出力シーケンスをシーケンス・ツー・ベクトルRNNに渡し、最後にその出力をソフトマックス層で処理してクラス確率を得る。訓練では、コスト関数として交差エントロピーを使う。<br />分類にオーディオも使いたい場合には、ストライドを指定した1次元畳み込み層のスタックを使って、1秒あたり数千のオーディオフレームを1秒に1フレームまで時間解像度を削減し（1秒あたりの画像数に合わせる）、出力シーケンスをシーケンス・ツー・ベクトルRNNに対する入力に連結する（最後の次元を使って）。</li>
</ul>
<p>問9、問10の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-16"></a>16章：RNNと注意機構による自然言語処理</h2>
<ul>
<li>1. ステートレスRNNは、RNNが訓練されたウィンドウのサイズ以下の長さのパターンしか捕捉できない。それに対し、ステートフルRNNなら長いパターンを捕捉できる。<br />しかし、ステートフルRNNは、ステートレスRNNよりも実装がかなり難しく、特にデータセットの適切な準備が難しい。また、連続するバッチがIIDではないなどの理由で、ステートフルRNNだから必ず性能がよくなるとは限らない。勾配降下法は、非IIDデータセットとは相性が悪い。</li>
<li>2. 一般に、1度に1つの単語を翻訳するという形で文を翻訳すると、とんでもない結果になる。たとえば、フランス語の&quot;Je vous en prie&quot;は&quot;You are welcome&quot;（どういたしまして）という意味だが、1度に1語ずつ訳すと&quot;I you in pray&quot;になってしまう。先に文全体を読んでからそれを翻訳する方がはるかによい。普通のシーケンス－シーケンスRNNは、最初の単語を読み込むとただちに文の翻訳を始めようとするが、エンコーダ－デコーダRNNは文全体を読んでから翻訳に取り掛かる。とは言え、次に何と言うかがはっきりしないときには「無言」を出力する（人間の同時通訳者のように）シーケンス－シーケンスRNNを考えることはできるだろう。</li>
<li>3. 可変長入力シーケンスは、短いシーケンスにパディングしてバッチ内のすべてのシーケンスが同じ長さになるようにするとともに、マスクを使ってRNNがパディングトークンを無視するようにすれば処理できる。性能を上げるために、同じような長さのシーケンスが含まれるようなバッチを作ることも心がけたい。不調和テンソルなら可変長シーケンスを保持できる。tf.kerasはいずれ不調和テンソルをサポートするようになるだろう。そうすれば、可変長入力シーケンスの処理は大幅に単純化される（本稿執筆時点ではまだそうなっていない）。<br />可変長出力シーケンスについては、その長さがあらかじめわかっている場合（たとえば、入力シーケンスと同じというような場合）には、EOS以降のトークンを無視するように損失関数を設定するだけでよい。そのモデルを使うコードも、EOSトークン以降を無視しなければならない。しかし、一般に出力シーケンスの長さは事前にはわからないので、そういう場合のソリューションは、個々のシーケンスの末尾でEOSトークンを出力するようにモデルを訓練することである。</li>
<li>4. たとえばニューラル機械翻訳システムなどで使われる訓練済みのエンコーダ－デコーダ・モデルの性能を向上させるために使われるテクニック。もっとも可能性の高そうな<span class="equation">\( k \)</span>種類（たとえばトップ3）の文の短いリストを管理し、デコーダステップのたびにそのリストを1語ずつ延ばす方法を探り、もっともよさそうな<span class="equation">\( k \)</span>種類の文だけを残す。パラメータ<span class="equation">\( k \)</span>は<b>ビーム幅</b>（beam width）と呼ばれ、大きくするとCPUとRAMの消費が増えるが、システムもより正確になる。<br />各ステップで同じ文を長くするために次の単語としてもっとも適切なものをどん欲に選ぶようなことをせずにこの方法を使えば、システムは複数の有望な文の可能性を同時に探れる。<br />TensorFlow Addonsを使えば、ビームサーチは簡単に実装できる。</li>
<li>5. 注意機構は、もともとエンコーダ－デコーダ・モデルで長い入力シーケンスを扱うために、デコーダがより直接的に入力シーケンスにアクセスできるようにするためのテクニックとして使われていた。デコーダの各タイムステップで、アライメントモデルがデコーダの現在の状態とエンコーダの全出力を処理し、個々の入力タイムステップのアライメントスコアを出力する。このスコアは、現在のデコーダタイムステップともっとも関連性の高い入力の部分を示す。そして、エンコーダ出力の加重総和（重みはアライメントスコア）をデコーダに渡し、デコーダが次のデコーダの状態とこのタイムステップの出力を生成する。<br />注意機構を使う最大のメリットは、エンコーダ－デコーダ・モデルが長い入力シーケンスを処理できるようになることである。アライメントスコアによってモデルがデバッグ、解釈しやすくなるというメリットもある。たとえば、モデルが誤りを犯した場合、モデルが入力のどの部分に注意を払っていたかがわかり、これが問題の診断に役立つことがある。注意機構は、多頭注意層としてTransformerアーキテクチャを支える存在にもなっている。次問解答を参照のこと。</li>
<li>6. 多頭注意層（オリジナルのTransformerアーキテクチャでは、6個のマスク済み多頭注意層を含む18個の多頭注意層が含まれていた）。BERTやGPT-2などの言語モデルを支える部品としても使われている。<br />多頭注意層の目的は、どの単語とどの単語がもっとも強く連携しているかを見きわめることであり、得られた文脈的な手がかりを使って個々の単語の表現を改良することである。</li>
<li>7. サンプリングソフトマックスは、クラスが非常に多いたとえば数千）分類モデルを訓練するときに使われる。モデルが正しいクラスを予測した単語のロジットと予測を誤った単語のサンプルのロジットに基づいて交差エントロピー損失の近似値を計算する。こうすると、すべてのロジットに基づいてソフトマックスを計算してから交差エントロピー損失を推計するのと比べてかなり訓練時間が短縮される。訓練後は、すべてのロジックに基づいてすべてのクラスの確率を計算する通常のソフトマックス関数を使って普通にモデルを使うことができる。</li>
</ul>
<p>問8から問11の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-17"></a>17章：オートエンコーダとGANを使った表現学習と生成型学習</h2>
<ul>
<li>1. 次の通り。<ul>
<li>特徴量の抽出。</li>
<li>教師なし事前学習。</li>
<li>次元削減。</li>
<li>モデルの生成。</li>
<li>異常検知（一般に、オートエンコーダは外れ値の再現が苦手である）。</li>
</ul>
</li>
</ul>
<ul>
<li>2. まず、データセット全体（ラベル付きのものもラベルなしのものも含めて）で深層オートエンコーダを訓練してから、その下位半分の層を分類器で再利用し（つまり、コーディング層までの層を再利用する）、ラベル付きデータを使って分類器を訓練する。ラベル付きデータがわずかしかない場合は、分類器を訓練するときに、再利用された層を凍結した方がよいだろう。</li>
<li>3. 必ずしも優れたものだとは言えない。<br />入力をコーディング層にコピーし、そのコーディング層を出力にコピーすることを学んだ過完備オートエンコーダになっている可能性が高い。実際、コーディング層のニューロンが1つだけでも、非常に深いオートエンコーダが個々の訓練インスタンスを別々のコーディングにマッピングすることを覚え（たとえば、第1インスタンスは0.001、第2インスタンスは0.002、第3インスタンスは0.003にマッピングする）、それらのコーディングに対応する正しい訓練インスタンスを「丸暗記」で再構築することを覚えることはできる。そのようなオートエンコーダは、入力を完璧に再構築しても、データに含まれる意味のあるパターンを学習しない。実際にそのようなマッピングが生まれることはあまり考えられないが、入力を完全に再構築できるからといってオートエンコーダが役に立つことを学習したとは限らないということは言える。しかし、再構築後の出力がひどければ、そのオートエンコーダの性能が低いことはほぼ間違いない。<br />オートエンコーダの性能は、たとえば最構築ロスを測定すれば評価できる（たとえば、出力と入力の差の二乗の平均であるMSEを計算する）。この場合も、再構築ロスが高ければオートエンコーダの性能が低いことを示す兆候になるが、再構築ロスが低いからといって必ずしもオートエンコーダの性能が高いわけではない。オートエンコーダは、その用途に基づいて評価することも大切だ。たとえば、分類器の教師なし事前学習のために使う場合には、分類器の性能も評価すべきである。</li>
<li>4. 不完備オートエンコーダとは、コーディング層が入力、出力層よりも小さいオートエンコーダである。コーディング層が入力、出力層よりも大きい場合には過完備オートエンコーダになる。<br />過度に不完備なオートエンコーダの最大のリスクは、入力の再構築に失敗する場合があることだ。<br />過完備オートエンコーダの最大のリスクは、役に立つ特徴量を学習せずに、入力をただ出力にコピーしてしまうことだ。</li>
<li>5. デコーダの重みをエンコーダの重みの転置に等しくすればよい。<br />重みを均等化すれば、モデルのパラメータ数が半減し、訓練データが少なくても訓練は早く収束するようになる。また、訓練セットを過学習するリスクが軽減される。</li>
<li>6. 訓練インスタンスによく似た出力を無作為に生成できるモデルのことである。たとえば、MNISTデータセットによる訓練が成功した生成的モデルは、リアルな数字イメージを無作為に生成できる。出力の分布は、訓練データの分布とほぼ同じになる。たとえば、MNISTには個々の数字のイメージが多数含まれているので、生成的モデルも1つひとつの数字についてほぼ同数のイメージを出力する。生成的モデルのなかには、たとえば生成する出力のタイプの制限などのパラメータを指定できるものもある。<br />生成的なオートエンコーダの例としては、変分オートエンコーダが挙げられる。</li>
<li>7. 相反する目標を持つ生成器と判別器の2つの部分から構成されるニューラルネットワーク・アーキテクチャのことである。生成器の目標は、訓練セットに含まれているものとよく似たインスタンスを生成して、判別器を出し抜くことである。判別器は、本物の画像と生成された画像を見分けなければならない。訓練イテレーションでは、判別器は通常の二項分類器のように訓練され、生成器は判別器の分類誤りを増やすように訓練される。<br />GANは、スーパー解像度、カラライゼーション、イメージ編集、単純なスケッチから写真のようにリアルな画像への変換、動画の次のフレームの予測などの高度な画像処理タスクで使われている。データセットの拡張（ほかのモデルの訓練用）、ほかのタイプのデータ（テキスト、オーディオ、時系列データなど）の生成、ほかのモデルの弱点の識別と強化にも使われている。</li>
<li>8. GANの訓練は、生成器と判別器の間で複雑なダイナミクスが働くため、きわめて難しい。最大の問題は、生成器の出力が似通ったものになるモード崩壊である。訓練が恐ろしく不安定になるという問題もある。訓練が最初のうちは順調だったのに、はっきりとした理由なしに大きく揺れたり反れたりしていくことがある。ハイパーパラメータの選択に過敏に反応するという問題もある。</li>
</ul>
<p>問9から問11の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-18"></a>18章：強化学習</h2>
<ul>
<li>1. 強化学習は、長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野である。<br />RLと通常の教師あり、教師なし学習には多くの違いがあり、以下に挙げるのはその一部だけである。<ul>
<li>教師あり、教師なし学習の目標は、一般にデータに含まれるパターンを見つけ、それを使って予測をすることだが、RLの目標は、優れた方策を見つけることである。</li>
<li>教師あり学習とは異なり、エージェントには明示的に「正解」が与えられない。エージェントは試行錯誤を通じて解を学習しなければならない。</li>
<li>教師なし学習とは異なり、報酬という教師的な存在がある。エージェントに対してタスクのしかたを教えたりはしないが、上達したり失敗したりしたときにはそのことを伝える。</li>
<li>RLエージェントは、環境の探索、報酬を得るための新しい方法の開発、すでに知っている報酬源の活用の間でバランスを取る必要がある。それに対し、教師あり、教師なし学習システムは、一般に探索について考える必要がなく、与えられた訓練データを消費するだけである。</li>
<li>教師あり学習、教師なし学習では、訓練インスタンスは一般に独立している（実際、一般にシャッフルされる）。強化学習では、連続する観察は、一般に独立ではない。エージェントはしばらく環境の同じ領域にとどまってから移動するので、隣接する観察には強い相関関係がある。そこで、訓練アルゴリズムに独立した観察を与えるために、再生メモリ（バッファ）が使われることがある。</li>
</ul>
</li>
</ul>
<ul>
<li>2. 次の通り。<ul>
<li><b>音楽のパーソナライゼーション</b><ul>
<li><b>環境</b>：ユーザーのパーソナライズされたウェブラジオ。</li>
<li><b>エージェント</b>：ユーザーのために次に再生する曲を決めるソフトウェア。</li>
<li><b>可能な行動</b>：カタログ内の曲を再生するか（ユーザーが喜びそうな曲を選ぶよう努力しなければならない）、広告を再生するか（ユーザーが興味を持ちそうな広告を選ぶよう努力しなければならない）。</li>
<li><b>報酬</b>：ユーザーが曲を聞いたら小さな正の報酬、広告を聞いたら大きな正の報酬、ユーザーが曲や広告をスキップしたら負の報酬、ユーザーが聞くのを止めたら大きな負の報酬。</li>
</ul>
</li>
<li><b>販売促進</b><ul>
<li><b>環境</b>：勤務先の販促部門。</li>
<li><b>エージェント</b>：プロフィールと購入履歴に基づいてキャンペーンメールを送る顧客を決めるソフトウェア。</li>
<li><b>可能な行動</b>：送信するかしないか（顧客ごと）。</li>
<li><b>報酬</b>：メールキャンペーンのコストという負の報酬と、キャンペーンによる推定売上という正の報酬。</li>
</ul>
</li>
<li><b>商品の配達</b><ul>
<li><b>環境</b>：運送会社。</li>
<li><b>エージェント</b>：トラック制御システム。</li>
<li><b>可能な行動</b>：倉庫で何を積み込むか、トラックをどこに向かって走らせるか、何を置いていくかなどを決めて配達用トラックを制御する。</li>
<li><b>報酬</b>：期限内に配達できるたびに正の報酬、遅れるたびに負の報酬。</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>3. 強化学習アルゴリズムは、行動の価値を推計するために、その行動から得られる報酬の合計を計算する。このとき、一般にすぐに得られる報酬には多めの重み、将来の報酬には少なめの重みを与える（行動は遠い未来よりも近未来に多くの影響を与えることを考慮している）。これをモデリングするために、一般にタイムステップごとに割引率を掛ける。たとえば、割引率が0.9なら、2タイムステップ先に受け取る100の報酬は、行動の価値を評価するときには<span class="equation">\( 0.9^2\times 100=81 \)</span>として扱われる。割引率は、現在と比べて未来にどの程度の価値を置くかの尺度だと考えることができる。1に近ければ、未来に現在とほぼ同じ価値を与えている。0に近ければ、目の前の報酬だけが大事だということになる。<br />割引率は最適な方策の評価に大きな影響を与える。未来に価値を置くなら、未来に得られるはずの報酬のために短期的に大きな痛みがあっても我慢するだろう。しかし、未来に価値を置かないなら、未来への投資など考えずに目の前にある報酬に飛びつくだろう。</li>
<li>4. 単純に得られる報酬を合計すれば測定できる。シミュレートされた環境では、多くのエピソードを実行して、平均の合計報酬を見ることができる（さらに、最小、最大の報酬、標準偏差などにも注目することになるだろう）。</li>
<li>5. 強化学習エージェントが報酬を受け取ったときに、過去の行動がその報酬にどれだけ貢献したかを直接知る方法がないこと。<br />行動してから報酬を受け取るまでに長い間が入るときによく起きる（たとえば、アタリの<b>Pong</b>（ピンポンゲーム）では、エージェントがボールを打ってからポイントを獲得するまでに数10タイムステップかかる場合がある）。<br />この問題は、可能ならエージェントに短期的な報酬を与えるようにすれば緩和できる。そのためには、通常タスクについての事前知識が必要になる。たとえば、チェスのプレイを学習するエージェントを作りたいときには、試合に勝ったときだけ報酬を与えるのではなく、敵の駒を取るたびに報酬を与えるとよい。</li>
<li>6. エージェントは、環境の同じ領域にしばらくとどまることが多く、その間の経験は互いによく似たものになる。これは、学習アルゴリズムに何らかの偏りをもたらす危険がある。環境のその領域に合わせて方策を最適化しても、その領域から外れた途端に方策の性能は下がってしまう。再生メモリは、この問題を解決するために使われる。エージェントは、もっとも新しい経験だけではなく、最近のものもそうでないものも含む過去の経験のバッファに基づいて学習する（私たちが夜に夢を見るのはそのためではないだろうか。その日の経験を再生して、そこからよりよく学習するのではないか）。</li>
<li>7. 方策オフRLアルゴリズムは、エージェントが異なる方策に従っても最適な方策の価値（つまり、エージェントが最適に行動したときに個々の状態から期待できる割引済みの将来の報酬の合計）を学習する。Q学習は、そのようなアルゴリズムの好例である。それに対し、方策オンアルゴリズムは、エージェントが実際に実行している方策（探索と利用の両方を含む）の価値を学習する。</li>
</ul>
<p>問8から問10の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>

<h2><a id="h-19"></a>19章：大規模なTensorFlowモデルの訓練とデプロイ</h2>
<ul>
<li>1. SavedModelには、TensorFlowモデルのアーキテクチャ（計算グラフ）と重みの両方が含まれている。<br />SavedModelは、計算グラフを定義するsaved_model.pbファイル（シリアライズされたプロトコルバッファという形になっている）と変数の値を格納するvariablesサブディレクトリを含むディレクトリという形で保存される。大量の重みを含むモデルでは、変数値は複数のファイルに分けて格納される。SavedModelには、モデルの語彙ファイル、クラス名、サンプルインスタンスなどの補助データを格納するassetsサブディレクトリも含まれている。<br />より正確に言うと、SavedModelは1個以上の<b>メタグラフ</b>（metagraph）を格納できる。メタグラフは計算グラフに関数シグネチャ定義（入出力の名前、型、形）を加えたものである。個々のメタグラフは、一連のタグによって識別される。<br />SavedModelの内容は、コマンドラインツールの<code class="tt">saved_model_cli</code>を使うか、<code class="tt">tf.saved_</code><code class="tt">model.load()</code>でこのツールをロードし、Python内で操作して調べる。</li>
<li>2. TF Servingは、複数のTensorFlowモデル（または同じモデルの複数のバージョン）をロードし、さまざまなアプリケーションからREST APIかgRPC APIでそれらに簡単にアクセスできるようにしたいときに使う。<br />アプリケーションで直接モデルを使うと、すべてのアプリケーションで一斉にモデルの新バージョンを使うのが難しくなる。TFモデルをラップする独自マイクロサービスを実装しようとすると、余分な作業が必要になる上に、TF Servingほどのものはなかなか作れない。<br />TF Servingにはさまざまな機能がある。ディレクトリを監視して追加されたモデルを自動的にデプロイできるので、新しいバージョンのモデルを使うためにアプリケーションを書き換えることはもちろん、再起動することさえ不要になる。高速で、十分にテストされており、スケーラビリティも高い。実験的なモデルのA/Bテストやユーザーのサブセットだけに新バージョンをデプロイするカナリアテストもサポートする。個々のリクエストをバッチにまとめGPUで一斉に実行することもできる。<br />TF Servingはソースからインストールすることもできるが、Dockerイメージを使ってインストールした方がはるかに簡単だ。TF Serving Dockerイメージのクラスタのデプロイでは、Kubernetesのようなコンテナオーケストレーションツールが使える。また、Google Cloud AI Platformのようなホステッドソリューションを使う方法もある。</li>
<li>3. それらのインスタンスが同じmodelsディレクトリを監視するように設定し、そのディレクトリにSavedModel形式で新モデルをエキスポートする。</li>
<li>4. gRPC APIはREST APIよりも効率がよいが、そのクライアントライブラリはREST APIほど広く使われていない。そして、REST APIで圧縮を有効にすると、パフォーマンスはほぼ同じになる。これらからgRPC APIは、できる限り高いパフォーマンスが必要で、クライアントがREST APIだけに制限されていないときにもっとも役立つ。</li>
<li>5. 次の通り。<ul>
<li>SavedModelを最適化できるコンバータを提供している。コンバータはモデルを縮小し、レイテンシを下げる。コンバータは、予測のために不要なオペレーション（訓練オペレーションなど）を切り捨て、可能な限りオペレーションを最適化、融合する。</li>
<li>コンバータは訓練後量子化も実行できる。このテクニックはモデルのサイズを大幅に削減し、ダウンロード、格納が大幅に高速化される。</li>
<li>最適化されたモデルをFlatBuffer形式で保存する。この形式ならパースなしでRAMに直接ロードできる。これによりロード時間が短縮され、メモリフットプリントが縮小される。</li>
</ul>
</li>
</ul>
<ul>
<li>6. 訓練中のモデルに疑似量子化オペレーションを追加すること。<br />モデルが量子化ノイズを無視することを学習できるようにして、最終的な重みが量子化によって大きく劣化しないようにするため。</li>
<li>7. 次の通り。<ul>
<li>モデル並列とは、訓練や予測をスピードアップするために、モデルを複数の部品に分解し、複数のデバイスを使ってそれらを並列実行することである。</li>
<li>データ並列とは、モデルの複数のレプリカを作って複数のデバイスにデプロイし、訓練中の各イテレーションでは、個々のレプリカに異なるデータバッチを与え、それぞれでモデルパラメータの損失の勾配を計算してそれらを平均すること。データ並列にはさらに次のようなバリアントがある。<ul>
<li>同期的なデータ並列では、すべてのレプリカの勾配を集計してオプティマイザが勾配降下ステップを実行する。パラメータを一元管理する方法（たとえばパラメータサーバーを使って）と、すべてのレプリカにパラメータをレプリケートしてAllReduceアルゴリズムで同期を取る方法がある。</li>
<li>非同期的なデータ並列では、パラメータを一元管理し、レプリカを独立して実行する。個々のレプリカはほかのレプリカの処理終了を待つことなく各訓練イテレーションの最後の段階で中央のパラメータディレクトリを直接更新する。</li>
</ul>
</li>
<li>一般に、訓練のスピードアップのためには、モデル並列よりもデータ並列の方が効果的だということがわかっている。これは、主としてデータ並列の方がデバイス間通信が少ないためである。しかも、データ並列は実装しやすく、どのモデルでも同じように機能する。モデル並列はモデルを解析してもっとも適切な分割方法を判断しなければならない。</li>
</ul>
</li>
</ul>
<ul>
<li>8. 次の通り。<ul>
<li><code class="tt">MultiWorkerMirroredStrategy</code>は、ミラーリング方式のデータ並列を実行する。モデルはすべての利用可能サーバーのすべてのデバイスにレプリケートされ、個々のレプリカは、各訓練イテレーションで別々のデータバッチを与えられ、それに基づいて勾配を計算する。分散AllReduce実装（デフォルトはNCCL）でそれらの勾配の平均を計算してその平均勾配をすべてのレプリカで共有する。その上ですべてのレプリカが同じ勾配降下ステップを実行する。この分散方式は、すべてのサーバーとデバイスが同じように扱われるためもっとも単純だが、高い性能を発揮する。一般にこの分散方式を使うようにすべきだ。最大の欠点は、すべてのレプリカのRAMにモデルが収まりきらなければならないことである。</li>
<li><code class="tt">ParameterServerStrategy</code>は、非同期データ並列を実行する。モデルはすべてのワーカーのすべてのデバイスにレプリケートされ、パラメータはすべてのパラメータサーバーで共有される。個々のワーカーは専用の訓練ループを持ち、互いに非同期に実行される。個々の訓練イテレーションで、個々のワーカーは専用のデータバッチを手に入れ、パラメータサーバーから最新バージョンのモデルパラメータをフェッチする。そして、それらのパラメータの損失の勾配を計算し、パラメータサーバーに送る。最後にパラメータサーバーが送られてきた勾配を使って勾配降下ステップを実行する。この分散方式は、一般に<code class="tt">MultiWorkerMirroredStrategy</code>よりも遅く、パラメータサーバーの管理が必要になる分デプロイが少し難しい。しかし、GPU RAMに収まりきらない巨大モデルの訓練では役に立つ。</li>
</ul>
</li>
</ul>
<p>問9から問11の解答は、<a href="https://github.com/ageron/handson-ml2" class="link">https://github.com/ageron/handson-ml2</a>のJupyterノートブックを参照のこと。</p>
</body>
</html>
